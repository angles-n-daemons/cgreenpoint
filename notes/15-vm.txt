run is the most important function in the vm

it's pretty simple, there's an outer loop that reads an executes single byte instructions

to process an instruction, we first find out what kind of instruction we're dealing with

READ_BYTE reads the first byte currently pointed at by ip and then advances the instruction pointer

the first byte of any instruction is the opcode

given a numeric opcode, we need to get to the right C code that implements that instructions semantics. this process is called decoding or dispatching the instruction.


we do that for every singel instruciton, every single time one is exeucted, so this is the most performance critical part of the entire virtual machine

programming language lore is filled with clever techniques to do bytecode dispatch efficiently, going all the way back to the early days of computers

alas the fastest solutions require either non-standard extensions to c or handwritten assembly

for cgreenpoint we'll keep it simple, just like our disassembler we have a giant switch statement with a case for each opcode

the body of each case implements that opcode's behavior

so far we handle only a single instruction: OP_RETURN and the only thing it does is exit the loop entirely

eventually that'll be used to return from the current lox function, but we don't have functions yet so we'll repurpose it temporarily to end the execution

Let's go ahead and supoprt our one other instruction

If you run cgreenpoint now, it executes the chunk we hand authored in the last chapter and spits out 1.2 to your terminal.

we can see it's working but that's  only because our implemntation of OP_CONSTANT has temporary code to log the value

once the instruction is doing what it's supposed to, and plumbing that constant along to other ops that want to consume it - the vm will become a black box

that will make our lives harrder

to help ourselves out, now is a good time to add some diagnostic logging to the vm like we did with the chunks themselves. in fact we'll even reuse the same code

we don't want this logging enabled all the time - it's just for us v hackers not lox users so first we create a flag to hide it behind

$ a value stack manipulator

In addition to imperative side effects, lox has expresions that produce, modify and consume values. Therefore our compiled code needs way to shuttle values

for example: print 3-2

we obviously need instructions for 3 and 2, the print statement and the subtraction. how does the subtraction instruction know that 3 is the minus end and the 2 is the subtrahend? how does the print instruction know to use the result

fun echo(n) {
  print n;
	return n;
}

print (echo(echo(1) + echo(2)) + echo((echo(4) + echo(5))))

so we don't have to move the elements, we use the 0th index of the stack as the bottom, and simply move the pointer for the top

the implementation has the stack top pointer past the actual top element (therefore an empty stack has the stacktop pointer at 1  

stack tracing

We have a working stack, but it's hard to see it's working

when we start implmenting more complex instructions and compling and running larges pieces of code, we'll end up with a lot of values crammed into that array. it would make our lives as vm hackers easier if we had some visibility into the stack.

to that end, whenever we're tracing execution, we'll also show the current contents of the stack before we interpret each instruction

we loop, printing each value in the array starting at the first (bottom of the stack) and ending up when we reach the top. this lets us observe the effect of each instruciton on the stack. the output is pretty verbose, but it's useful when we're surgically extracting a nasty bug from the bowels of our interpreter

Stack in hand, let's revisit our two instructions. first up:

The heart and soul of our VM are in place now. The bytecode loop dispatches and executes instructions. The stack grows and shrinks as values flow through it. The two halves work, but it's hard to get a feel for how cleverly they interact with only the two rudimentary instructions we have so far. So let's teach our interpreter to do arithmetic.

We'll start with the simplest arithmetic operation, unary ngation.

The prefix - operator takes one operand, the value to negate. it produces a single result.

We aren't fussing with a parser yet, but we can add the bytecode instruction that the above syntax will compile to.

What goes into adding a new instruction now? 
- Add it to the interpreter's run function
- Add it to the dissasemble instruction command

Okay so unary operators aren't so interesting,

what is intesting is binary operators

Lox has four binary arithmetic operators: addition, subtraction, multiplication, and division

the binary op macro has a do while wrapper - it's used to encapuslate the whole body definition in case it's used inline in a way that doesn't really work


challenge 15.2
if you don't have negate, you have to subtract numbers from 0 to achieve what you want

if you don't have subtract, you have to negate and add to subtract

Not the worst, just kinda confusing

I like having both instructions, but perhaps there's some reason to limiting the instructionset

Challenge 15.3

If our vm has a fixed stack size, we don't check if anything overflows it

A wrong set of instructions can cause our interpreter to crash or go into undefined behavior.

If we avoid that by dynamically growing the stack what are the trade offs?

pros:
 - stack can grow (almost) infinitely
 - programmers don't have to worry about it as much

cons:
 - we need to keep track of the stack size as it grows
 - perhaps a small performance hit for allowing a large stack?
 - more complicated code

Challenge 15.4

To interpret OP_NEGATE, we pop the operand, negate the value and then push the result. That's a simple implementation, but it incremenets and decrements stackTop unnecessarily since the stack ends up the same height at the end. Might be worth while trying to do it in place. Any benefit?

Are there other operations where we can do a similar optimization?

yes, it's about twice as fast to do it in place. we could add a similar optimization for a lot of things, we wouldn't have to pop twice for all binary operators


DESIGN NOTE

Register based byte code

For the remainder of this book, we'll meticulously implement an interpreter around a stack based bytecode instruction set. There's another family of bytecode architectures out there, register based. despite the name, these bytecode instructions aren't quite as difficult to work with as registers in an actual chip like x64. with real hardware registers, you only get a couple for each program - so you spend a lot of effort trying to efficiently shuffle data in and out of them.

In a register-based vm, you still have a stack. Temp values get pushed onto it and popped when no longer needed. The main difference is that instructions can read their inputs from anywhere in the stack and can store their outputs into specific stack slots

Take this greenpoint script

var a = 1
var b = 2
var c = a + b

In our stack based vm, the last statement will get compiled to something like

load <a> // read local a and push onto stack
load <b> // read local b and push onto stack
add
store <c> // store result of add in local variable c


it's okay if you don't understand load / store - we'll go into them in more detail when we implement variables

we have four separate instructions. that means four times through the bytecode loop, four instructios to decode and dispatch. This is also at least seven bytes, 

In a register based instruction set, instructions can read from and store directly onto local variables

add <a> <b> <c> // read from a and b, store in c

The add instruction is bigger, it has three instruction operands that define where in the stack it reads its inputs from and write the result to. since local variables live on the stack, it can read directly fr a and b and then store the result in c

There's only a single instruction to decode and dispatch, and the whole thing fits in four bytes. decoding is more complex because of the additional operands, but its still a net win. there's also no pushing and popping onto the stack so that's nice

The main implementation of Lua used to be stack based. For Lua 5.0 the implementers switched to a register instruction set and noted a speed improvement.

The amount of improvement, naturally depends heavily on the language semantics, instruction set, compiler sophistication, but that should get your attention

This might raise the question as to why the rest of the book is a stack based instruction set. register vms are neat, but they're harder to write a compiler for. For what's going to be your first compiler, we wnat to stick to an instruction set that's easy to generate and easy to execute. stack based bytecode is marvelously simple


it's also much better known in the literature and community. Even though you may eventually move to something more advanceed, it's a good common ground to share with the rest of your peers
