run is the most important function in the vm

it's pretty simple, there's an outer loop that reads an executes single byte instructions

to process an instruction, we first find out what kind of instruction we're dealing with

READ_BYTE reads the first byte currently pointed at by ip and then advances the instruction pointer

the first byte of any instruction is the opcode

given a numeric opcode, we need to get to the right C code that implements that instructions semantics. this process is called decoding or dispatching the instruction.


we do that for every singel instruciton, every single time one is exeucted, so this is the most performance critical part of the entire virtual machine

programming language lore is filled with clever techniques to do bytecode dispatch efficiently, going all the way back to the early days of computers

alas the fastest solutions require either non-standard extensions to c or handwritten assembly

for cgreenpoint we'll keep it simple, just like our disassembler we have a giant switch statement with a case for each opcode

the body of each case implements that opcode's behavior

so far we handle only a single instruction: OP_RETURN and the only thing it does is exit the loop entirely

eventually that'll be used to return from the current lox function, but we don't have functions yet so we'll repurpose it temporarily to end the execution

Let's go ahead and supoprt our one other instruction

If you run cgreenpoint now, it executes the chunk we hand authored in the last chapter and spits out 1.2 to your terminal.

we can see it's working but that's  only because our implemntation of OP_CONSTANT has temporary code to log the value

once the instruction is doing what it's supposed to, and plumbing that constant along to other ops that want to consume it - the vm will become a black box

that will make our lives harrder

to help ourselves out, now is a good time to add some diagnostic logging to the vm like we did with the chunks themselves. in fact we'll even reuse the same code

we don't want this logging enabled all the time - it's just for us v hackers not lox users so first we create a flag to hide it behind

$ a value stack manipulator

In addition to imperative side effects, lox has expresions that produce, modify and consume values. Therefore our compiled code needs way to shuttle values

for example: print 3-2

we obviously need instructions for 3 and 2, the print statement and the subtraction. how does the subtraction instruction know that 3 is the minus end and the 2 is the subtrahend? how does the print instruction know to use the result

fun echo(n) {
  print n;
	return n;
}

print (echo(echo(1) + echo(2)) + echo((echo(4) + echo(5))))

so we don't have to move the elements, we use the 0th index of the stack as the bottom, and simply move the pointer for the top

the implementation has the stack top pointer past the actual top element (therefore an empty stack has the stacktop pointer at 1  

stack tracing

We have a working stack, but it's hard to see it's working

when we start implmenting more complex instructions and compling and running larges pieces of code, we'll end up with a lot of values crammed into that array. it would make our lives as vm hackers easier if we had some visibility into the stack.

to that end, whenever we're tracing execution, we'll also show the current contents of the stack before we interpret each instruction

we loop, printing each value in the array starting at the first (bottom of the stack) and ending up when we reach the top. this lets us observe the effect of each instruciton on the stack. the output is pretty verbose, but it's useful when we're surgically extracting a nasty bug from the bowels of our interpreter

Stack in hand, let's revisit our two instructions. first up:

The heart and soul of our VM are in place now. The bytecode loop dispatches and executes instructions. The stack grows and shrinks as values flow through it. The two halves work, but it's hard to get a feel for how cleverly they interact with only the two rudimentary instructions we have so far. So let's teach our interpreter to do arithmetic.

We'll start with the simplest arithmetic operation, unary ngation.

The prefix - operator takes one operand, the value to negate. it produces a single result.

We aren't fussing with a parser yet, but we can add the bytecode instruction that the above syntax will compile to.

What goes into adding a new instruction now? 
- Add it to the interpreter's run function
- Add it to the dissasemble instruction command

Okay so unary operators aren't so interesting,

what is intesting is binary operators

Lox has four binary arithmetic operators: addition, subtraction, multiplication, and division

the binary op macro has a do while wrapper - it's used to encapuslate the whole body definition in case it's used inline in a way that doesn't really work


challenge 15.2
if you don't have negate, you have to subtract numbers from 0 to achieve what you want

if you don't have subtract, you have to negate and add to subtract

Not the worst, just kinda confusing

I like having both instructions, but perhaps there's some reason to limiting the instructionset

Challenge 15.3

If our vm has a fixed stack size, we don't check if anything overflows it

A wrong set of instructions can cause our interpreter to crash or go into undefined behavior.

If we avoid that by dynamically growing the stack what are the trade offs?

pros:
 - stack can grow (almost) infinitely
 - programmers don't have to worry about it as much

cons:
 - we need to keep track of the stack size as it grows
 - perhaps a small performance hit for allowing a large stack?
 - more complicated code

Challenge 15.4

To interpret OP_NEGATE, we pop the operand, negate the value and then push the result. That's a simple implementation, but it incremenets and decrements stackTop unnecessarily since the stack ends up the same height at the end. Might be worth while trying to do it in place. Any benefit?

Are there other operations where we can do a similar optimization?

yes, it's about twice as fast to do it in place. we could add a similar optimization for a lot of things, we wouldn't have to pop twice for all binary operators
